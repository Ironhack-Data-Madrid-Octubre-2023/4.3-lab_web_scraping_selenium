{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Selenium Doc](https://www.selenium.dev/documentation/)\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `Selenium` and `pandas` are imported for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "# Searching Method:\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Controlling the time:\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait   \n",
    "\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver import ActionChains as AC\n",
    "# from selenium.webdriver.common.keys import Keys  \n",
    "\n",
    "# To Display the HTML\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable the options you may need. In the next cell you have an example of them but you can choose to use them or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = webdriver.FirefoxOptions()\n",
    "driver = webdriver.Firefox(options = PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse, and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/trending/developers'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ismail Pelaseyed\\nhomanp',\n",
       " 'Chris Banes\\nchrisbanes',\n",
       " 'Travis Cline\\ntmc',\n",
       " 'Xiaoyu Zhang\\nBBuf',\n",
       " 'Stefan Prodan\\nstefanprodan',\n",
       " 'Pedro Cattori\\npcattori',\n",
       " 'lllyasviel',\n",
       " 'Arvin Xu\\narvinxx',\n",
       " 'Howard Wu\\nhowardwu',\n",
       " 'Shahed Nasser\\nshahednasser',\n",
       " 'Kailash Nadh\\nknadh',\n",
       " 'Mattt\\nmattt',\n",
       " 'kixelated',\n",
       " 'Brad Fitzpatrick\\nbradfitz',\n",
       " 'Miško Hevery\\nmhevery',\n",
       " 'Andrew Lock\\nandrewlock',\n",
       " 'Brian Smith\\nbriansmith',\n",
       " 'Numan\\nnumandev1',\n",
       " 'Fons van der Plas\\nfonsp',\n",
       " 'Leonid Bugaev\\nbuger',\n",
       " 'wū yāng\\nuyarn',\n",
       " 'Steven Nguyen\\nstnguyen90',\n",
       " 'Argo Zhang\\nArgoZhang',\n",
       " 'Josh Stein\\njcstein']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[driver.find_elements(By.XPATH, f'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article[{i}]/div[2]/div[1]/div[1]')[0].text \n",
    " for i in range(1, 25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/trending/python?since=daily'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataelement / bisheng',\n",
       " 'hiroi-sora / Umi-OCR',\n",
       " 'public-apis-dev / public-apis',\n",
       " 'THUDM / ChatGLM3',\n",
       " 'yunjey / pytorch-tutorial',\n",
       " 'huggingface / transformers',\n",
       " 'AILab-CVC / VideoCrafter',\n",
       " 'swisskyrepo / PayloadsAllTheThings',\n",
       " 'ageitgey / face_recognition',\n",
       " 'facebookresearch / llama',\n",
       " 'lm-sys / FastChat',\n",
       " 'pytorch / pytorch',\n",
       " 'gto76 / python-cheatsheet',\n",
       " 'microsoft / DeepSpeed',\n",
       " 'SkyworkAI / Skywork',\n",
       " 'THUDM / ChatGLM-6B',\n",
       " 'facebookresearch / fairseq',\n",
       " 'Azure-Samples / chat-with-your-data-solution-accelerator',\n",
       " 'PaddlePaddle / PaddleOCR',\n",
       " 'tatsu-lab / stanford_alpaca',\n",
       " 'minimaxir / big-list-of-naughty-strings',\n",
       " 'safevideo / autollm',\n",
       " 'langchain-ai / langchain',\n",
       " 'bregman-arie / devops-exercises']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[driver.find_elements(By.XPATH, f'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article[{i}]/h2/a')[0].text \n",
    " for i in range(1, 25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG\">Link image #1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png\">Link image #2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg/220px-Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg\">Link image #3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg\">Link image #4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/220px-Steamboat-willie.jpg\">Link image #5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5, 10):\n",
    "    link = driver.find_elements(By.TAG_NAME, 'img')[i].get_attribute('src')\n",
    "    display(HTML(f'<a href=\"{link}\">Link image #{i-4}</a>')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://en.wikipedia.org/wiki/Python'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://en.wikipedia.org/wiki/Python#bodyContent\">Link image #1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://en.wikipedia.org/wiki/Main_Page\">Link image #2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://en.wikipedia.org/wiki/Wikipedia:Contents\">Link image #3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://en.wikipedia.org/wiki/Portal:Current_events\">Link image #4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://en.wikipedia.org/wiki/Special:Random\">Link image #5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    link = driver.find_elements(By.TAG_NAME, 'a')[i].get_attribute('href')\n",
    "    display(HTML(f'<a href=\"{link}\">Link image #{i+1}</a>')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://uscode.house.gov/download/download.shtml'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title 20 - Education', \"Title 38 - Veterans' Benefits ٭\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[driver.find_elements(By.CLASS_NAME, 'usctitlechanged')[i].text \n",
    " for i in range(len(driver.find_elements(By.CLASS_NAME, 'usctitlechanged')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.fbi.gov/wanted/topten'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [driver.find_elements(By.CSS_SELECTOR, 'li.portal-type-person:nth-child(2)')[i].text\n",
    "#  for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, '/html/body/div[5]/a/div').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [driver.find_elements(By.CLASS_NAME, 'tbdat')[i].text.split('\\n')[0] for i in range(1, 22)]\n",
    "time_ = [driver.find_elements(By.CLASS_NAME, 'tago')[i].text for i in range(0, 21)]\n",
    "latitude = [driver.find_elements(By.CLASS_NAME, 'tblat')[i].text.split('\\n')[0] for i in range(1, 22)]\n",
    "longitude = [driver.find_elements(By.CLASS_NAME, 'tblon')[i].text.split('\\n')[0] for i in range(1, 22)]\n",
    "region = [driver.find_elements(By.CLASS_NAME, 'tbreg')[i].text.split('\\n')[0] for i in range(1, 22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-02 13:44:44</td>\n",
       "      <td>11 min ago</td>\n",
       "      <td>28.100</td>\n",
       "      <td>-16.081</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-02 13:39:42</td>\n",
       "      <td>16 min ago</td>\n",
       "      <td>31.611</td>\n",
       "      <td>-104.275</td>\n",
       "      <td>WESTERN TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-02 13:30:57</td>\n",
       "      <td>25 min ago</td>\n",
       "      <td>12.650</td>\n",
       "      <td>-88.330</td>\n",
       "      <td>OFFSHORE EL SALVADOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-02 12:59:51</td>\n",
       "      <td>56 min ago</td>\n",
       "      <td>38.843</td>\n",
       "      <td>-122.871</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-02 12:58:38</td>\n",
       "      <td>57 min ago</td>\n",
       "      <td>38.200</td>\n",
       "      <td>20.750</td>\n",
       "      <td>GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-02 12:58:21</td>\n",
       "      <td>57 min ago</td>\n",
       "      <td>34.565</td>\n",
       "      <td>-97.498</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-02 12:51:44</td>\n",
       "      <td>1 hr 04 min ago</td>\n",
       "      <td>17.898</td>\n",
       "      <td>-66.790</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-02 12:47:37</td>\n",
       "      <td>1 hr 08 min ago</td>\n",
       "      <td>38.506</td>\n",
       "      <td>39.638</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-11-02 12:47:28</td>\n",
       "      <td>1 hr 08 min ago</td>\n",
       "      <td>31.659</td>\n",
       "      <td>-104.392</td>\n",
       "      <td>WESTERN TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-11-02 12:46:08</td>\n",
       "      <td>1 hr 09 min ago</td>\n",
       "      <td>37.937</td>\n",
       "      <td>36.224</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-11-02 12:43:14</td>\n",
       "      <td>1 hr 12 min ago</td>\n",
       "      <td>-5.650</td>\n",
       "      <td>102.780</td>\n",
       "      <td>SOUTHERN SUMATRA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-11-02 12:30:05</td>\n",
       "      <td>1 hr 25 min ago</td>\n",
       "      <td>63.927</td>\n",
       "      <td>28.681</td>\n",
       "      <td>FINLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-11-02 12:21:43</td>\n",
       "      <td>1 hr 34 min ago</td>\n",
       "      <td>45.956</td>\n",
       "      <td>1.403</td>\n",
       "      <td>FRANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-11-02 12:04:07</td>\n",
       "      <td>1 hr 51 min ago</td>\n",
       "      <td>31.664</td>\n",
       "      <td>-104.396</td>\n",
       "      <td>WESTERN TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-11-02 11:57:17</td>\n",
       "      <td>1 hr 58 min ago</td>\n",
       "      <td>40.254</td>\n",
       "      <td>31.936</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-11-02 11:55:27</td>\n",
       "      <td>2 hr 00 min ago</td>\n",
       "      <td>46.874</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>FRANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-11-02 11:43:32</td>\n",
       "      <td>2 hr 12 min ago</td>\n",
       "      <td>38.060</td>\n",
       "      <td>23.840</td>\n",
       "      <td>GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-11-02 11:35:32</td>\n",
       "      <td>2 hr 20 min ago</td>\n",
       "      <td>38.091</td>\n",
       "      <td>37.747</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-11-02 11:32:26</td>\n",
       "      <td>2 hr 23 min ago</td>\n",
       "      <td>-21.050</td>\n",
       "      <td>-69.010</td>\n",
       "      <td>TARAPACA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-11-02 11:13:51</td>\n",
       "      <td>2 hr 42 min ago</td>\n",
       "      <td>44.228</td>\n",
       "      <td>7.476</td>\n",
       "      <td>NORTHERN ITALY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-11-02 11:13:05</td>\n",
       "      <td>2 hr 42 min ago</td>\n",
       "      <td>38.959</td>\n",
       "      <td>43.697</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date             time latitude longitude  \\\n",
       "0   2023-11-02 13:44:44       11 min ago   28.100   -16.081   \n",
       "1   2023-11-02 13:39:42       16 min ago   31.611  -104.275   \n",
       "2   2023-11-02 13:30:57       25 min ago   12.650   -88.330   \n",
       "3   2023-11-02 12:59:51       56 min ago   38.843  -122.871   \n",
       "4   2023-11-02 12:58:38       57 min ago   38.200    20.750   \n",
       "5   2023-11-02 12:58:21       57 min ago   34.565   -97.498   \n",
       "6   2023-11-02 12:51:44  1 hr 04 min ago   17.898   -66.790   \n",
       "7   2023-11-02 12:47:37  1 hr 08 min ago   38.506    39.638   \n",
       "8   2023-11-02 12:47:28  1 hr 08 min ago   31.659  -104.392   \n",
       "9   2023-11-02 12:46:08  1 hr 09 min ago   37.937    36.224   \n",
       "10  2023-11-02 12:43:14  1 hr 12 min ago   -5.650   102.780   \n",
       "11  2023-11-02 12:30:05  1 hr 25 min ago   63.927    28.681   \n",
       "12  2023-11-02 12:21:43  1 hr 34 min ago   45.956     1.403   \n",
       "13  2023-11-02 12:04:07  1 hr 51 min ago   31.664  -104.396   \n",
       "14  2023-11-02 11:57:17  1 hr 58 min ago   40.254    31.936   \n",
       "15  2023-11-02 11:55:27  2 hr 00 min ago   46.874    -0.295   \n",
       "16  2023-11-02 11:43:32  2 hr 12 min ago   38.060    23.840   \n",
       "17  2023-11-02 11:35:32  2 hr 20 min ago   38.091    37.747   \n",
       "18  2023-11-02 11:32:26  2 hr 23 min ago  -21.050   -69.010   \n",
       "19  2023-11-02 11:13:51  2 hr 42 min ago   44.228     7.476   \n",
       "20  2023-11-02 11:13:05  2 hr 42 min ago   38.959    43.697   \n",
       "\n",
       "                          region  \n",
       "0   CANARY ISLANDS, SPAIN REGION  \n",
       "1                  WESTERN TEXAS  \n",
       "2           OFFSHORE EL SALVADOR  \n",
       "3            NORTHERN CALIFORNIA  \n",
       "4                         GREECE  \n",
       "5                       OKLAHOMA  \n",
       "6             PUERTO RICO REGION  \n",
       "7                 EASTERN TURKEY  \n",
       "8                  WESTERN TEXAS  \n",
       "9                 CENTRAL TURKEY  \n",
       "10   SOUTHERN SUMATRA, INDONESIA  \n",
       "11                       FINLAND  \n",
       "12                        FRANCE  \n",
       "13                 WESTERN TEXAS  \n",
       "14                WESTERN TURKEY  \n",
       "15                        FRANCE  \n",
       "16                        GREECE  \n",
       "17                CENTRAL TURKEY  \n",
       "18               TARAPACA, CHILE  \n",
       "19                NORTHERN ITALY  \n",
       "20                EASTERN TURKEY  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"date\": date,\n",
    "    \"time\": time_,\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude,\n",
    "    \"region\": region})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://twitter.com/elonmusk'\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elon Musk', '32,7 mil posts']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.XPATH, '/html/body/div[1]/div/div/div[2]/main/div/div/div/div[1]/div/div[1]/div[1]/div/div/div/div/div/div[2]/div')[0].text.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'161,8 M Seguidores'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.CSS_SELECTOR, 'div.r-1mf7evn:nth-child(2) > a:nth-child(1)')[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161,8 M Seguidores\n",
      "The user ñujul do not exist\n"
     ]
    }
   ],
   "source": [
    "user_list = ['elonmusk', 'ñujul']\n",
    "\n",
    "for i in user_list:\n",
    "    try:\n",
    "        url = f'https://twitter.com/{i}'\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        print(driver.find_elements(By.CSS_SELECTOR, 'div.r-1mf7evn:nth-child(2) > a:nth-child(1)')[0].text)\n",
    "    except:\n",
    "        print(f'The user {i} do not exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.wikipedia.org/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th># of Articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Español</td>\n",
       "      <td>1 892 000+ artículos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>6 715 000+ articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>日本語</td>\n",
       "      <td>1 387 000+ 記事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Русский</td>\n",
       "      <td>1 938 000+ статей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deutsch</td>\n",
       "      <td>2 836 000+ Artikel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Français</td>\n",
       "      <td>2 553 000+ articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Italiano</td>\n",
       "      <td>1 826 000+ voci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中文</td>\n",
       "      <td>1 377 000+ 条目 / 條目</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Português</td>\n",
       "      <td>1 109 000+ artigos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>العربية</td>\n",
       "      <td>1 217 000+ مقالة</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language         # of Articles\n",
       "0    Español  1 892 000+ artículos\n",
       "1    English   6 715 000+ articles\n",
       "2        日本語         1 387 000+ 記事\n",
       "3    Русский     1 938 000+ статей\n",
       "4    Deutsch    2 836 000+ Artikel\n",
       "5   Français   2 553 000+ articles\n",
       "6   Italiano       1 826 000+ voci\n",
       "7         中文    1 377 000+ 条目 / 條目\n",
       "8  Português    1 109 000+ artigos\n",
       "9    العربية      1 217 000+ مقالة"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictio = {}\n",
    "\n",
    "dictio['Language'] = [driver.find_elements(By.XPATH, '/html/body/div[2]')[0].text.split('\\n')[i] for i in range(0,20,2)]\n",
    "dictio['# of Articles'] = [driver.find_elements(By.XPATH, '/html/body/div[2]')[0].text.split('\\n')[i] for i in range(1,20,2)]\n",
    "\n",
    "df = pd.DataFrame(dictio)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.gov.uk/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[driver.find_elements(By.XPATH, '/html/body/div[3]/main/div[3]/div/ul')[0].text.split('\\n')[i] for i in range(0,28,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = []\n",
    "speakers = []\n",
    "lang_dicc = {}\n",
    "\n",
    "for i in range(1, 11):\n",
    "    rows = driver.find_element(By.XPATH, f'//table//tbody//tr[{i}]').text.split('\\n')\n",
    "    try:\n",
    "        if rows[1] != None:\n",
    "            language.append(rows[0])\n",
    "            speakers.append(rows[1].split(')')[1].split(' ')[1])\n",
    "    except:\n",
    "        language.append(rows[0].split(' ')[0])\n",
    "        speakers.append(rows[0].split(' ')[1])\n",
    "\n",
    "lang_dicc['Language'] = language\n",
    "lang_dicc['Speakers (mill)'] = speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Speakers (mill)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Language Native speakers</td>\n",
       "      <td>Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Russian</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yue Chinese</td>\n",
       "      <td>86.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Language Speakers (mill)\n",
       "0  Language Native speakers        Language\n",
       "1          Mandarin Chinese             939\n",
       "2                   Spanish             485\n",
       "3                   English             380\n",
       "4                     Hindi             345\n",
       "5                Portuguese             236\n",
       "6                   Bengali             234\n",
       "7                   Russian             147\n",
       "8                  Japanese             123\n",
       "9               Yue Chinese            86.1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(lang_dicc)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://twitter.com/elonmusk'\n",
    "driver.get(url)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Next I’m buying Coca-Cola to put the cocaine back in']\n",
      "['I hope that even my worst critics remain on Twitter, because that is what free speech means']\n",
      "['Let’s make Twitter maximum fun!']\n",
      "[' Yesss!!! ']\n",
      "['Listen, I can’t do miracles ok']\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    print(driver.find_elements(By.TAG_NAME, 'article')[i].text.split('\\n')[4:-3])\n",
    "    time.sleep(5)\n",
    "    num = random.randint(-100, 200)\n",
    "    driver.execute_script(f'window.scrollTo(0, {num});')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/chart/top'\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_path = '//*[@id=\"list-view-option-detailed\"]'\n",
    "driver.find_elements(By.XPATH, x_path)[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "top_250 = {'Movie': [],'Release Year': [], 'Direction': [], 'Stars': []}\n",
    "\n",
    "for i in range(250):\n",
    "    top_250['Movie'].append(driver.find_elements(By.CSS_SELECTOR, 'div.ipc-metadata-list-summary-item__c')[i].text.split('\\n')[0].split('.')[1])\n",
    "    top_250['Release Year'].append(driver.find_elements(By.CSS_SELECTOR, 'div.ipc-metadata-list-summary-item__c')[i].text.split('\\n')[1])\n",
    "    rest = driver.find_elements(By.CSS_SELECTOR, 'div.ipc-metadata-list-summary-item__c')[i].text.split('\\n')[8]\n",
    "    for i in range(len(rest)):\n",
    "        if rest[i].islower() and rest[i + 1].isupper():\n",
    "            rest = rest[:i + 1] + \",\" + rest[i + 1:]\n",
    "            dire = rest.split(',')\n",
    "    top_250['Direction'].append(dire[1])\n",
    "    top_250['Stars'].append(dire[3:])\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Los cuatrocientos golpes</td>\n",
       "      <td>1959</td>\n",
       "      <td>François Truffaut</td>\n",
       "      <td>[Jean-Pierre Léaud, Albert Rémy, Claire Maurier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Persona</td>\n",
       "      <td>1966</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "      <td>[Bibi Andersson, Liv Ullmann, Margaretha Krook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>La vida de Brian</td>\n",
       "      <td>1979</td>\n",
       "      <td>Terry Jones</td>\n",
       "      <td>[Graham Chapman, John Cleese, Michael Palin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Aladdín</td>\n",
       "      <td>1992</td>\n",
       "      <td>Ron Clements</td>\n",
       "      <td>[Scott Weinger, Robin Williams, Linda Larkin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Bailando con lobos</td>\n",
       "      <td>1990</td>\n",
       "      <td>Kevin Costner</td>\n",
       "      <td>[Kevin Costner, Mary Mc, Donnell, Graham Greene]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Movie Release Year          Direction  \\\n",
       "245   Los cuatrocientos golpes         1959  François Truffaut   \n",
       "246                    Persona         1966     Ingmar Bergman   \n",
       "247           La vida de Brian         1979        Terry Jones   \n",
       "248                    Aladdín         1992       Ron Clements   \n",
       "249         Bailando con lobos         1990      Kevin Costner   \n",
       "\n",
       "                                                Stars  \n",
       "245  [Jean-Pierre Léaud, Albert Rémy, Claire Maurier]  \n",
       "246   [Bibi Andersson, Liv Ullmann, Margaretha Krook]  \n",
       "247      [Graham Chapman, John Cleese, Michael Palin]  \n",
       "248     [Scott Weinger, Robin Williams, Linda Larkin]  \n",
       "249  [Kevin Costner, Mary Mc, Donnell, Graham Greene]  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_250 = pd.DataFrame(top_250)\n",
    "top_250.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.imdb.com/chart/top'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_path = '//*[@id=\"list-view-option-detailed\"]'\n",
    "driver.find_elements(By.XPATH, x_path)[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "top_10 = {'Movie': [],'Release Year': [], 'Summary': []}\n",
    "\n",
    "for i in random.sample(range(1, 250), 10):\n",
    "    top_10['Movie'].append(driver.find_elements(By.CSS_SELECTOR, 'div.ipc-metadata-list-summary-item__c')[i].text.split('\\n')[0].split('.')[1])\n",
    "    top_10['Release Year'].append(driver.find_elements(By.CSS_SELECTOR, 'div.ipc-metadata-list-summary-item__c')[i].text.split('\\n')[1])\n",
    "    top_10['Summary'].append(driver.find_elements(By.CSS_SELECTOR, 'div.ipc-metadata-list-summary-item__c')[i].text.split('\\n')[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La leyenda del indomable</td>\n",
       "      <td>1967</td>\n",
       "      <td>Un tranquilo sureño es sentenciado a dos años ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La guerra de las galaxias</td>\n",
       "      <td>1977</td>\n",
       "      <td>Luke Skywalker une sus fuerzas con un caballer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El gigante de hierro</td>\n",
       "      <td>1999</td>\n",
       "      <td>Un joven se hace amigo de un robot gigante del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fargo</td>\n",
       "      <td>1996</td>\n",
       "      <td>Los crímenes de Jerry Lundegaard se caen a ped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo que el viento se llevó</td>\n",
       "      <td>1939</td>\n",
       "      <td>La manipuladora hija del propietario de una pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>1994</td>\n",
       "      <td>Las presidencias de Kennedy y Johnson, los aco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sucedió una noche</td>\n",
       "      <td>1934</td>\n",
       "      <td>Una heredera malcriada huye de su familia y re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>El chico</td>\n",
       "      <td>1921</td>\n",
       "      <td>Un vagabundo cuida de un niño abandonado, pero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Reservoir Dogs</td>\n",
       "      <td>1992</td>\n",
       "      <td>Cuando un sencillo robo de joyas acaba terribl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>1976</td>\n",
       "      <td>Un boxeador poco conocido tiene la gran oportu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Movie Release Year  \\\n",
       "0    La leyenda del indomable         1967   \n",
       "1   La guerra de las galaxias         1977   \n",
       "2        El gigante de hierro         1999   \n",
       "3                       Fargo         1996   \n",
       "4   Lo que el viento se llevó         1939   \n",
       "5                Forrest Gump         1994   \n",
       "6           Sucedió una noche         1934   \n",
       "7                    El chico         1921   \n",
       "8              Reservoir Dogs         1992   \n",
       "9                       Rocky         1976   \n",
       "\n",
       "                                             Summary  \n",
       "0  Un tranquilo sureño es sentenciado a dos años ...  \n",
       "1  Luke Skywalker une sus fuerzas con un caballer...  \n",
       "2  Un joven se hace amigo de un robot gigante del...  \n",
       "3  Los crímenes de Jerry Lundegaard se caen a ped...  \n",
       "4  La manipuladora hija del propietario de una pl...  \n",
       "5  Las presidencias de Kennedy y Johnson, los aco...  \n",
       "6  Una heredera malcriada huye de su familia y re...  \n",
       "7  Un vagabundo cuida de un niño abandonado, pero...  \n",
       "8  Cuando un sencillo robo de joyas acaba terribl...  \n",
       "9  Un boxeador poco conocido tiene la gran oportu...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10 = pd.DataFrame(top_10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the city:madrid\n"
     ]
    }
   ],
   "source": [
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?' + 'q=' + city + '&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invalid API key. Please see https://openweathermap.org/faq#error401 for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = {'Title': [],'Price': [], 'Stock': []}\n",
    "\n",
    "for i in range(10):\n",
    "    books['Title'].append(driver.find_elements(By.TAG_NAME, 'article')[i].text.split('\\n')[0])\n",
    "    books['Price'].append(driver.find_elements(By.TAG_NAME, 'article')[i].text.split('\\n')[1])\n",
    "    books['Stock'].append(driver.find_elements(By.TAG_NAME, 'article')[i].text.split('\\n')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the ...</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History ...</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>£22.65</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Dirty Little Secrets ...</td>\n",
       "      <td>£33.34</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Coming Woman: A ...</td>\n",
       "      <td>£17.93</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Boys in the ...</td>\n",
       "      <td>£22.60</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>£52.15</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Title   Price     Stock\n",
       "0            A Light in the ...  £51.77  In stock\n",
       "1            Tipping the Velvet  £53.74  In stock\n",
       "2                    Soumission  £50.10  In stock\n",
       "3                 Sharp Objects  £47.82  In stock\n",
       "4  Sapiens: A Brief History ...  £54.23  In stock\n",
       "5               The Requiem Red  £22.65  In stock\n",
       "6  The Dirty Little Secrets ...  £33.34  In stock\n",
       "7       The Coming Woman: A ...  £17.93  In stock\n",
       "8           The Boys in the ...  £22.60  In stock\n",
       "9               The Black Maria  £52.15  In stock"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.DataFrame(books)\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
