{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Selenium Doc](https://www.selenium.dev/documentation/)\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `Selenium` and `pandas` are imported for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable the options you may need. In the next cell you have an example of them but you can choose to use them or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver configuration\n",
    "opciones=Options()\n",
    "\n",
    "opciones.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "opciones.add_experimental_option('useAutomationExtension', False)\n",
    "opciones.headless=False    # si True, no aperece la ventana (headless=no visible)\n",
    "opciones.add_argument('--start-maximized')         # comienza maximizado\n",
    "#opciones.add_argument('user-data-dir=selenium')    # mantiene las cookies\n",
    "#opciones.add_extension('driver_folder/adblock.crx')       # adblocker\n",
    "opciones.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(opciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse, and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = driver.find_elements(By.CSS_SELECTOR, 'article')[0].text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = article[1]\n",
    "nick = article[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = [e.text.split('\\n')[1] for e in driver.find_elements(By.CSS_SELECTOR, 'article')\n",
    "         if e.text.split('\\n')[0].isnumeric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nicks = [e.text.split('\\n')[2] for e in driver.find_elements(By.CSS_SELECTOR, 'article')\n",
    "         if e.text.split('\\n')[0].isnumeric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['homanp',\n",
       " 'chrisbanes',\n",
       " 'tmc',\n",
       " 'BBuf',\n",
       " 'stefanprodan',\n",
       " 'pcattori',\n",
       " 'POPULAR REPO',\n",
       " 'arvinxx',\n",
       " 'howardwu',\n",
       " 'shahednasser',\n",
       " 'knadh',\n",
       " 'mattt',\n",
       " 'POPULAR REPO',\n",
       " 'bradfitz',\n",
       " 'mhevery',\n",
       " 'andrewlock',\n",
       " 'briansmith',\n",
       " 'numandev1',\n",
       " 'fonsp',\n",
       " 'buger',\n",
       " 'uyarn',\n",
       " 'stnguyen90',\n",
       " 'ArgoZhang',\n",
       " 'jcstein',\n",
       " 'mikermcneil']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = []\n",
    "for i in range(len(names)):\n",
    "    if nicks[i] != 'POPULAR REPO':\n",
    "        users.append(f'{names[i]} ({nicks[i]})')\n",
    "    else:\n",
    "        users.append(f'{names[i]}')\n",
    "        \n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ismail Pelaseyed (homanp)',\n",
       " 'Chris Banes (chrisbanes)',\n",
       " 'Travis Cline (tmc)',\n",
       " 'Xiaoyu Zhang (BBuf)',\n",
       " 'Stefan Prodan (stefanprodan)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PayloadsAllTheThings'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_elements(By.CSS_SELECTOR, 'h2.h3.lh-condensed')[0].text.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repositories = [e.text.split()[-1] for e in driver.find_elements(By.CSS_SELECTOR, 'h2.h3.lh-condensed')]\n",
    "\n",
    "len(repositories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PayloadsAllTheThings', 'ChatGLM3', 'PaddleOCR', 'langchain', 'bisheng']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repositories[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG',\n",
       " 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = [e.get_attribute('src') for e in driver.find_elements(By.CSS_SELECTOR, 'img.mw-file-element')][2:]\n",
    "\n",
    "imgs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, '//*[@id=\"mw-content-text\"]/div[1]/ul[2]/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Python_(programming_language)#bodyContent',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = [e.get_attribute('href') for e in driver.find_elements(By.CSS_SELECTOR, 'a')]\n",
    "\n",
    "links[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title 20 - Education', \"Title 38 - Veterans' Benefits ٭\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed = [e.text for e in driver.find_elements(By.CSS_SELECTOR, 'div.usctitlechanged')]\n",
    "\n",
    "changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARNOLDO JIMENEZ',\n",
       " 'OMAR ALEXANDER CARDENAS',\n",
       " 'YULAN ADONAY ARCHAGA CARIAS',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'DONALD EUGENE FIELDS II',\n",
       " 'RUJA IGNATOVA',\n",
       " 'WILVER VILLEGAS-PALOMINO',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'ALEXIS FLORES',\n",
       " 'JOSE RODOLFO VILLARREAL-HERNANDEZ']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_wanted = [e.text for e in driver.find_elements(By.CSS_SELECTOR, 'li.portal-type-person.castle-grid-block-item')]\n",
    "\n",
    "most_wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scroll down to load whole table\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = driver.find_element(By.CSS_SELECTOR, 'table.eqs.table-scroll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Citizen response',\n",
       " 'Date & Time UTC',\n",
       " 'Lat. degrees',\n",
       " 'Lon. degrees',\n",
       " 'Depth km',\n",
       " 'Mag.[+]',\n",
       " 'Region']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [e.text.replace('\\n', ' ') for e in table.find_element(By.CSS_SELECTOR, 'thead').find_elements(By.CSS_SELECTOR, 'th')][1:]\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = table.find_element(By.CSS_SELECTOR, 'tbody').find_elements(By.CSS_SELECTOR, 'tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-11-01 15:14:13\\n15 min ago'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0].find_elements(By.CSS_SELECTOR, 'td')[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2023-11-01 15:14:13\\n24 min ago',\n",
       "  '36.891',\n",
       "  '-2.999',\n",
       "  '13',\n",
       "  '2.2',\n",
       "  'STRAIT OF GIBRALTAR'],\n",
       " ['2023-11-01 15:09:09\\n29 min ago',\n",
       "  '11.840',\n",
       "  '125.640',\n",
       "  '19',\n",
       "  '3.0',\n",
       "  'SAMAR, PHILIPPINES']]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_data = []\n",
    "\n",
    "for r in rows:\n",
    "    data = [e for e in r.find_elements(By.CSS_SELECTOR, 'td')]\n",
    "    \n",
    "    temp = []\n",
    "    for d in data:\n",
    "        if d.text:\n",
    "            temp.append(d.text)\n",
    "            \n",
    "    row_data.append(temp)\n",
    "    \n",
    "row_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Citizen response',\n",
       " 'Date & Time UTC',\n",
       " 'Lat. degrees',\n",
       " 'Lon. degrees',\n",
       " 'Depth km',\n",
       " 'Mag.[+]',\n",
       " 'Region']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "earthquakes = pd.DataFrame(row_data, columns=columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date &amp; Time UTC</th>\n",
       "      <th>Lat. degrees</th>\n",
       "      <th>Lon. degrees</th>\n",
       "      <th>Depth km</th>\n",
       "      <th>Mag.[+]</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01 15:14:13\\n24 min ago</td>\n",
       "      <td>36.891</td>\n",
       "      <td>-2.999</td>\n",
       "      <td>13</td>\n",
       "      <td>2.2</td>\n",
       "      <td>STRAIT OF GIBRALTAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-01 15:09:09\\n29 min ago</td>\n",
       "      <td>11.840</td>\n",
       "      <td>125.640</td>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SAMAR, PHILIPPINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-01 15:03:32\\n35 min ago</td>\n",
       "      <td>40.528</td>\n",
       "      <td>-123.568</td>\n",
       "      <td>5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-01 14:49:46\\n48 min ago</td>\n",
       "      <td>59.976</td>\n",
       "      <td>10.946</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SOUTHERN NORWAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-01 14:45:25\\n53 min ago</td>\n",
       "      <td>0.140</td>\n",
       "      <td>124.260</td>\n",
       "      <td>75</td>\n",
       "      <td>3.5</td>\n",
       "      <td>MINAHASA, SULAWESI, INDONESIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Date & Time UTC Lat. degrees Lon. degrees Depth km Mag.[+]  \\\n",
       "0  2023-11-01 15:14:13\\n24 min ago       36.891       -2.999       13     2.2   \n",
       "1  2023-11-01 15:09:09\\n29 min ago       11.840      125.640       19     3.0   \n",
       "2  2023-11-01 15:03:32\\n35 min ago       40.528     -123.568        5     2.4   \n",
       "3  2023-11-01 14:49:46\\n48 min ago       59.976       10.946        8     3.0   \n",
       "4  2023-11-01 14:45:25\\n53 min ago        0.140      124.260       75     3.5   \n",
       "\n",
       "                          Region  \n",
       "0            STRAIT OF GIBRALTAR  \n",
       "1             SAMAR, PHILIPPINES  \n",
       "2            NORTHERN CALIFORNIA  \n",
       "3                SOUTHERN NORWAY  \n",
       "4  MINAHASA, SULAWESI, INDONESIA  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "account = 'chocu_'\n",
    "\n",
    "url = f'https://twitter.com/{account}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(opciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'48,7 mil posts'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = driver.find_element(By.CSS_SELECTOR, '#react-root > div > div > div.css-1dbjc4n.r-18u37iz.r-13qz1uu.r-417010 > main > div > div > div > div > div > div.css-1dbjc4n.r-aqfbo4.r-gtdqiz.r-1gn8etr.r-1g40b8q > div:nth-child(1) > div > div > div > div > div > div.css-1dbjc4n.r-16y2uox.r-1wbh5a2.r-1pi2tsx.r-1777fci > div > div')\n",
    "\n",
    "tweets.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(account):\n",
    "    \n",
    "    url = f'https://twitter.com/{account}'\n",
    "    \n",
    "    driver = webdriver.Chrome(opciones)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        selector = '#react-root > div > div > div.css-1dbjc4n.r-18u37iz.r-13qz1uu.r-417010 > main > div > div > div > div > div > div.css-1dbjc4n.r-aqfbo4.r-gtdqiz.r-1gn8etr.r-1g40b8q > div:nth-child(1) > div > div > div > div > div > div.css-1dbjc4n.r-16y2uox.r-1wbh5a2.r-1pi2tsx.r-1777fci > div > div'\n",
    "        \n",
    "        number = driver.find_element(By.CSS_SELECTOR, selector).text\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        number = 0\n",
    "     \n",
    "    driver.quit()\n",
    "    \n",
    "    return number     \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'102,5 mil posts'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tweets('RataUnderground')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "account = 'chocu_'\n",
    "\n",
    "url = f'https://twitter.com/{account}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'35,8 mil'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followers = driver.find_element(By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[5]/div[2]/a/span[1]/span').text\n",
    "\n",
    "followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_followers(account):\n",
    "    \n",
    "    url = f'https://twitter.com/{account}'\n",
    "    \n",
    "    driver = webdriver.Chrome(opciones)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        selector = '#react-root > div > div > div.css-1dbjc4n.r-18u37iz.r-13qz1uu.r-417010 > main > div > div > div > div > div > div:nth-child(3) > div > div > div > div > div.css-1dbjc4n.r-13awgt0.r-18u37iz.r-1w6e6rj > div:nth-child(2) > a > span.css-901oao.css-16my406.r-1nao33i.r-poiln3.r-1b43r93.r-b88u0q.r-1cwl3u0.r-bcqeeo.r-qvutc0 > span'\n",
    "        \n",
    "        number = driver.find_element(By.CSS_SELECTOR, selector).text\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        number = 0\n",
    "     \n",
    "    driver.quit()\n",
    "    \n",
    "    return number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_followers('RatUnderground') # me sale error porque me bloqueó twitter de tanto acceder a la web pero funciona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body = driver.find_element(By.CSS_SELECTOR, 'div.central-featured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langs = body.find_elements(By.CSS_SELECTOR, 'strong')\n",
    "nums = body.find_elements(By.CSS_SELECTOR, 'small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langs = [e.text for e in langs]\n",
    "\n",
    "nums = [e.text.split('+')[0] for e in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Español': '1 892 000',\n",
       " 'English': '6 715 000',\n",
       " '日本語': '1 387 000',\n",
       " 'Русский': '1 938 000',\n",
       " 'Deutsch': '2 836 000',\n",
       " 'Français': '2 553 000',\n",
       " 'Italiano': '1 826 000',\n",
       " '中文': '1 377 000',\n",
       " 'Português': '1 109 000',\n",
       " 'العربية': '1 217 000'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(langs, nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business and economy'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_list = driver.find_element(By.CSS_SELECTOR, 'ul.govuk-list.dgu-topics__list')\n",
    "\n",
    "ds_list.find_elements(By.CSS_SELECTOR, 'li')[0].text.split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = [e.text.split('\\n')[0] for e in ds_list.find_elements(By.CSS_SELECTOR, 'li')]\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = driver.find_element(By.CSS_SELECTOR, 'table.wikitable.sortable.static-row-numbers.jquery-tablesorter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Language', 'Native speakers (millions)', 'Language family', 'Branch']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [e.text.replace('\\n', ' ') for e in table.find_elements(By.CSS_SELECTOR, 'th')]\n",
    "\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = table.find_elements(By.CSS_SELECTOR, 'tr')[1:]\n",
    "\n",
    "rows = [e.find_elements(By.CSS_SELECTOR, 'td') for e in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mandarin Chinese (incl. Standard Chinese, but excl. other varieties)',\n",
       "  '939',\n",
       "  'Sino-Tibetan',\n",
       "  'Sinitic']]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(10):\n",
    "    temp = []\n",
    "    \n",
    "    for d in rows[i]:\n",
    "        temp.append(d.text.replace('\\n', ' '))\n",
    "        \n",
    "    data.append(temp)\n",
    "    \n",
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Native speakers (millions)</th>\n",
       "      <th>Language family</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mandarin Chinese (incl. Standard Chinese, but ...</td>\n",
       "      <td>939</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>485</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>380</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi (excl. Urdu, and other languages)</td>\n",
       "      <td>345</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>236</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>234</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russian</td>\n",
       "      <td>147</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>123</td>\n",
       "      <td>Japonic</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yue Chinese (incl. Cantonese)</td>\n",
       "      <td>86.1</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>Vietic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Language  \\\n",
       "0  Mandarin Chinese (incl. Standard Chinese, but ...   \n",
       "1                                            Spanish   \n",
       "2                                            English   \n",
       "3            Hindi (excl. Urdu, and other languages)   \n",
       "4                                         Portuguese   \n",
       "5                                            Bengali   \n",
       "6                                            Russian   \n",
       "7                                           Japanese   \n",
       "8                      Yue Chinese (incl. Cantonese)   \n",
       "9                                         Vietnamese   \n",
       "\n",
       "  Native speakers (millions) Language family        Branch  \n",
       "0                        939    Sino-Tibetan       Sinitic  \n",
       "1                        485   Indo-European       Romance  \n",
       "2                        380   Indo-European      Germanic  \n",
       "3                        345   Indo-European    Indo-Aryan  \n",
       "4                        236   Indo-European       Romance  \n",
       "5                        234   Indo-European    Indo-Aryan  \n",
       "6                        147   Indo-European  Balto-Slavic  \n",
       "7                        123         Japonic      Japanese  \n",
       "8                       86.1    Sino-Tibetan       Sinitic  \n",
       "9                       85.0   Austroasiatic        Vietic  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['movie_name', 'initial_release', 'director_name', 'stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top = driver.find_element(By.CSS_SELECTOR, 'ul.ipc-metadata-list.ipc-metadata-list--dividers-between.sc-9d2f6de0-0.ckQYbL.compact-list-view.ipc-metadata-list--base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.imdb.com/title/tt0111161/?ref_=chttp_t_1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top.find_elements(By.CSS_SELECTOR, 'a.ipc-title-link-wrapper')[0].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = [e.get_attribute('href') for e in top.find_elements(By.CSS_SELECTOR, 'a.ipc-title-link-wrapper')]\n",
    "\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver.get(links[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9,2/10'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/h1/span').text\n",
    "\n",
    "initial_release = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/ul/li[1]/a').text\n",
    "\n",
    "director_name = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section[4]/ul/li[1]/div/ul/li/a').text\n",
    "\n",
    "stars = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[3]/div[2]/div[2]/div[1]/div/div[1]/a/span/div/div[2]/div[1]').text.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section[4]/ul/li[1]/div/ul/li/a\"}\n  (Session info: chrome=119.0.6045.106); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF71A0F82B2+55298]\n\t(No symbol) [0x00007FF71A065E02]\n\t(No symbol) [0x00007FF719F205AB]\n\t(No symbol) [0x00007FF719F6175C]\n\t(No symbol) [0x00007FF719F618DC]\n\t(No symbol) [0x00007FF719F9CBC7]\n\t(No symbol) [0x00007FF719F820EF]\n\t(No symbol) [0x00007FF719F9AAA4]\n\t(No symbol) [0x00007FF719F81E83]\n\t(No symbol) [0x00007FF719F5670A]\n\t(No symbol) [0x00007FF719F57964]\n\tGetHandleVerifier [0x00007FF71A470AAB+3694587]\n\tGetHandleVerifier [0x00007FF71A4C728E+4048862]\n\tGetHandleVerifier [0x00007FF71A4BF173+4015811]\n\tGetHandleVerifier [0x00007FF71A1947D6+695590]\n\t(No symbol) [0x00007FF71A070CE8]\n\t(No symbol) [0x00007FF71A06CF34]\n\t(No symbol) [0x00007FF71A06D062]\n\t(No symbol) [0x00007FF71A05D3A3]\n\tBaseThreadInitThunk [0x00007FFA52F67344+20]\n\tRtlUserThreadStart [0x00007FFA53C226B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m initial_release \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__next\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/ul/li[1]/a\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     11\u001b[0m temp\u001b[38;5;241m.\u001b[39mappend(initial_release)\n\u001b[1;32m---> 12\u001b[0m director_name \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__next\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/main/div/section[1]/div/section/div/div[1]/section[4]/ul/li[1]/div/ul/li/a\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     13\u001b[0m temp\u001b[38;5;241m.\u001b[39mappend(director_name)\n\u001b[0;32m     14\u001b[0m stars \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__next\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/main/div/section[1]/section/div[3]/section/section/div[3]/div[2]/div[2]/div[1]/div/div[1]/a/span/div/div[2]/div[1]\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:738\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    735\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    736\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:344\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    345\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section[4]/ul/li[1]/div/ul/li/a\"}\n  (Session info: chrome=119.0.6045.106); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF71A0F82B2+55298]\n\t(No symbol) [0x00007FF71A065E02]\n\t(No symbol) [0x00007FF719F205AB]\n\t(No symbol) [0x00007FF719F6175C]\n\t(No symbol) [0x00007FF719F618DC]\n\t(No symbol) [0x00007FF719F9CBC7]\n\t(No symbol) [0x00007FF719F820EF]\n\t(No symbol) [0x00007FF719F9AAA4]\n\t(No symbol) [0x00007FF719F81E83]\n\t(No symbol) [0x00007FF719F5670A]\n\t(No symbol) [0x00007FF719F57964]\n\tGetHandleVerifier [0x00007FF71A470AAB+3694587]\n\tGetHandleVerifier [0x00007FF71A4C728E+4048862]\n\tGetHandleVerifier [0x00007FF71A4BF173+4015811]\n\tGetHandleVerifier [0x00007FF71A1947D6+695590]\n\t(No symbol) [0x00007FF71A070CE8]\n\t(No symbol) [0x00007FF71A06CF34]\n\t(No symbol) [0x00007FF71A06D062]\n\t(No symbol) [0x00007FF71A05D3A3]\n\tBaseThreadInitThunk [0x00007FFA52F67344+20]\n\tRtlUserThreadStart [0x00007FFA53C226B1+33]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for link in links:\n",
    "    temp = []\n",
    "    \n",
    "    driver.get(link)\n",
    "    \n",
    "    movie_name = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/h1/span').text\n",
    "    temp.append(movie_name)\n",
    "    initial_release = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/ul/li[1]/a').text\n",
    "    temp.append(initial_release)\n",
    "    director_name = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section[4]/ul/li[1]/div/ul/li/a').text\n",
    "    temp.append(director_name)\n",
    "    stars = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[3]/div[2]/div[2]/div[1]/div/div[1]/a/span/div/div[2]/div[1]').text.replace('\\n', '')\n",
    "    temp.append(stars)\n",
    "    \n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me reventó a los 44, mi ordenador es muy lento así que no voy a volverlo a intentar, ya en coger estos 44 tardó 15 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>initial_release</th>\n",
       "      <th>director_name</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cadena perpetua</td>\n",
       "      <td>1994</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>9,3/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El padrino</td>\n",
       "      <td>1972</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>9,2/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El caballero oscuro</td>\n",
       "      <td>2008</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>9,0/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El padrino (parte II)</td>\n",
       "      <td>1974</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>9,0/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 hombres sin piedad</td>\n",
       "      <td>1957</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>9,0/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La lista de Schindler</td>\n",
       "      <td>1993</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>9,0/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>El señor de los anillos: El retorno del rey</td>\n",
       "      <td>2003</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>9,0/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>1994</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>8,9/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>El señor de los anillos: La comunidad del anillo</td>\n",
       "      <td>2001</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8,8/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>El bueno, el feo y el malo</td>\n",
       "      <td>1966</td>\n",
       "      <td>Sergio Leone</td>\n",
       "      <td>8,8/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>1994</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>8,8/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>El club de la lucha</td>\n",
       "      <td>1999</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>8,8/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>El señor de los anillos: Las dos torres</td>\n",
       "      <td>2002</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8,8/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Origen</td>\n",
       "      <td>2010</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>8,8/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>El imperio contraataca</td>\n",
       "      <td>1980</td>\n",
       "      <td>Irvin Kershner</td>\n",
       "      <td>8,7/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Matrix</td>\n",
       "      <td>1999</td>\n",
       "      <td>Lana Wachowski</td>\n",
       "      <td>8,7/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Uno de los nuestros</td>\n",
       "      <td>1990</td>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>8,7/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Alguien voló sobre el nido del cuco</td>\n",
       "      <td>1975</td>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>8,7/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Seven</td>\n",
       "      <td>1995</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>¡Qué bello es vivir!</td>\n",
       "      <td>1946</td>\n",
       "      <td>Frank Capra</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Los siete samuráis</td>\n",
       "      <td>1954</td>\n",
       "      <td>Akira Kurosawa</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>2014</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>8,7/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>El silencio de los corderos</td>\n",
       "      <td>1991</td>\n",
       "      <td>Jonathan Demme</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Spider-Man: Cruzando el multiverso</td>\n",
       "      <td>2023</td>\n",
       "      <td>Joaquim Dos Santos</td>\n",
       "      <td>8,7/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Salvar al soldado Ryan</td>\n",
       "      <td>1998</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ciudad de Dios</td>\n",
       "      <td>2002</td>\n",
       "      <td>Fernando Meirelles</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>La vida es bella</td>\n",
       "      <td>1997</td>\n",
       "      <td>Roberto Benigni</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>La milla verde</td>\n",
       "      <td>1999</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>La guerra de las galaxias</td>\n",
       "      <td>1977</td>\n",
       "      <td>George Lucas</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Terminator 2: El juicio final</td>\n",
       "      <td>1991</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Regreso al futuro</td>\n",
       "      <td>1985</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>El viaje de Chihiro</td>\n",
       "      <td>2001</td>\n",
       "      <td>Hayao Miyazaki</td>\n",
       "      <td>8,6/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>El pianista</td>\n",
       "      <td>2002</td>\n",
       "      <td>Roman Polanski</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Psicosis</td>\n",
       "      <td>1960</td>\n",
       "      <td>Alfred Hitchcock</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Parásitos</td>\n",
       "      <td>2019</td>\n",
       "      <td>Bong Joon Ho</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Gladiator (El gladiador)</td>\n",
       "      <td>2000</td>\n",
       "      <td>Ridley Scott</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>El rey león</td>\n",
       "      <td>1994</td>\n",
       "      <td>Roger Allers</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>El profesional (Léon)</td>\n",
       "      <td>1994</td>\n",
       "      <td>Luc Besson</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>American History X</td>\n",
       "      <td>1998</td>\n",
       "      <td>Tony Kaye</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Infiltrados</td>\n",
       "      <td>2006</td>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>2014</td>\n",
       "      <td>Damien Chazelle</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>El truco final (El prestigio)</td>\n",
       "      <td>2006</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Sospechosos habituales</td>\n",
       "      <td>1995</td>\n",
       "      <td>Bryan Singer</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>La tumba de las luciérnagas</td>\n",
       "      <td>1988</td>\n",
       "      <td>Isao Takahata</td>\n",
       "      <td>8,5/10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          movie_name initial_release  \\\n",
       "0                                    Cadena perpetua            1994   \n",
       "1                                         El padrino            1972   \n",
       "2                                El caballero oscuro            2008   \n",
       "3                              El padrino (parte II)            1974   \n",
       "4                              12 hombres sin piedad            1957   \n",
       "5                              La lista de Schindler            1993   \n",
       "6        El señor de los anillos: El retorno del rey            2003   \n",
       "7                                       Pulp Fiction            1994   \n",
       "8   El señor de los anillos: La comunidad del anillo            2001   \n",
       "9                         El bueno, el feo y el malo            1966   \n",
       "10                                      Forrest Gump            1994   \n",
       "11                               El club de la lucha            1999   \n",
       "12           El señor de los anillos: Las dos torres            2002   \n",
       "13                                            Origen            2010   \n",
       "14                            El imperio contraataca            1980   \n",
       "15                                            Matrix            1999   \n",
       "16                               Uno de los nuestros            1990   \n",
       "17               Alguien voló sobre el nido del cuco            1975   \n",
       "18                                             Seven            1995   \n",
       "19                              ¡Qué bello es vivir!            1946   \n",
       "20                                Los siete samuráis            1954   \n",
       "21                                      Interstellar            2014   \n",
       "22                       El silencio de los corderos            1991   \n",
       "23                Spider-Man: Cruzando el multiverso            2023   \n",
       "24                            Salvar al soldado Ryan            1998   \n",
       "25                                    Ciudad de Dios            2002   \n",
       "26                                  La vida es bella            1997   \n",
       "27                                    La milla verde            1999   \n",
       "28                         La guerra de las galaxias            1977   \n",
       "29                     Terminator 2: El juicio final            1991   \n",
       "30                                 Regreso al futuro            1985   \n",
       "31                               El viaje de Chihiro            2001   \n",
       "32                                       El pianista            2002   \n",
       "33                                          Psicosis            1960   \n",
       "34                                         Parásitos            2019   \n",
       "35                          Gladiator (El gladiador)            2000   \n",
       "36                                       El rey león            1994   \n",
       "37                             El profesional (Léon)            1994   \n",
       "38                                American History X            1998   \n",
       "39                                       Infiltrados            2006   \n",
       "40                                          Whiplash            2014   \n",
       "41                     El truco final (El prestigio)            2006   \n",
       "42                            Sospechosos habituales            1995   \n",
       "43                       La tumba de las luciérnagas            1988   \n",
       "\n",
       "           director_name   stars  \n",
       "0         Frank Darabont  9,3/10  \n",
       "1   Francis Ford Coppola  9,2/10  \n",
       "2      Christopher Nolan  9,0/10  \n",
       "3   Francis Ford Coppola  9,0/10  \n",
       "4           Sidney Lumet  9,0/10  \n",
       "5       Steven Spielberg  9,0/10  \n",
       "6          Peter Jackson  9,0/10  \n",
       "7      Quentin Tarantino  8,9/10  \n",
       "8          Peter Jackson  8,8/10  \n",
       "9           Sergio Leone  8,8/10  \n",
       "10       Robert Zemeckis  8,8/10  \n",
       "11         David Fincher  8,8/10  \n",
       "12         Peter Jackson  8,8/10  \n",
       "13     Christopher Nolan  8,8/10  \n",
       "14        Irvin Kershner  8,7/10  \n",
       "15        Lana Wachowski  8,7/10  \n",
       "16       Martin Scorsese  8,7/10  \n",
       "17          Milos Forman  8,7/10  \n",
       "18         David Fincher  8,6/10  \n",
       "19           Frank Capra  8,6/10  \n",
       "20        Akira Kurosawa  8,6/10  \n",
       "21     Christopher Nolan  8,7/10  \n",
       "22        Jonathan Demme  8,6/10  \n",
       "23    Joaquim Dos Santos  8,7/10  \n",
       "24      Steven Spielberg  8,6/10  \n",
       "25    Fernando Meirelles  8,6/10  \n",
       "26       Roberto Benigni  8,6/10  \n",
       "27        Frank Darabont  8,6/10  \n",
       "28          George Lucas  8,6/10  \n",
       "29         James Cameron  8,6/10  \n",
       "30       Robert Zemeckis  8,5/10  \n",
       "31        Hayao Miyazaki  8,6/10  \n",
       "32        Roman Polanski  8,5/10  \n",
       "33      Alfred Hitchcock  8,5/10  \n",
       "34          Bong Joon Ho  8,5/10  \n",
       "35          Ridley Scott  8,5/10  \n",
       "36          Roger Allers  8,5/10  \n",
       "37            Luc Besson  8,5/10  \n",
       "38             Tony Kaye  8,5/10  \n",
       "39       Martin Scorsese  8,5/10  \n",
       "40       Damien Chazelle  8,5/10  \n",
       "41     Christopher Nolan  8,5/10  \n",
       "42          Bryan Singer  8,5/10  \n",
       "43         Isao Takahata  8,5/10  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
